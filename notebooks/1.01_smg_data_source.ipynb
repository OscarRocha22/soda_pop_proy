{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21d7bfa5",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# <font color= #f6c049> **Soda Pop Project: Data Source** </font>\n",
    "#### <font color= #2E9AFE> `Deep Learning`</font>\n",
    "<Strong> Sofía Maldonado, Óscar Josué Rocha & Viviana Toledo </Strong>\n",
    "\n",
    "_27/02/2026._\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5d12b5",
   "metadata": {},
   "source": [
    "This proyect aims to create an autoencoder that can generate images of the cans for 6 different sodas. These are:\n",
    "- Coca-Cola\n",
    "- Pepsi\n",
    "- Fanta\n",
    "- Sprite\n",
    "- Dr. Pepper\n",
    "- Canada Dry\n",
    "\n",
    "The first step is to obtain the images themselves, from the internet. We decided to use Google Images for this, as it was the fastest way to get access to many different images on the same page, which made scraping them easier. The process for obtaining the images contains two steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4baeadc",
   "metadata": {},
   "source": [
    "1. Perform a search on _Google Images_. Using the console available on the web browser, download the displayed images URLs with the following code, which will store the URLs on a CSV file:\n",
    "\n",
    "``` javascript\n",
    "const urls = Array.from(document.querySelectorAll('img'))\n",
    "  .map(img => img.src)\n",
    "  .filter(src => src.startsWith('http'));\n",
    "\n",
    "const csvContent = 'url\\n' + urls.join('\\n');\n",
    "\n",
    "const blob = new Blob([csvContent], { type: 'text/csv;charset=utf-8;' });\n",
    "const link = document.createElement('a');\n",
    "link.href = URL.createObjectURL(blob);\n",
    "link.download = 'urls.csv';\n",
    "document.body.appendChild(link);\n",
    "link.click();\n",
    "document.body.removeChild(link);\n",
    "URL.revokeObjectURL(link.href);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8784e4d",
   "metadata": {},
   "source": [
    "2. With the URLs for the images in the CSV files, the next step was to download them. This was done with a very simple Go script. This was written in Go because as the task involved downloading thousands of images, and Go is a faster language than Python, so the process would be faster. There are also more robust web scraping tools in Go that work better on stingy websites like Google, in comparison to Python.\n",
    "\n",
    "The script opens each of the CSV files. For each one, it reads the image URL and downloads the image in question with the name of whichever soda it is (it gets this information from the name of the CSV file). The original CSV files can be found in `/data/raw`. The Go script used can be found in `/references/main.go`\n",
    "\n",
    "After running the code, we ended up with 4582 images. Due to the nature of Google Images, some of these images weren't particularly useful for our model, so we decided to manually carve out images that weren't useful, either for their small size, or because there were other elements in the image that would confuse the neural network. In the end, we ended up having **XXXX** images, which were saved to `~/data/external`."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
